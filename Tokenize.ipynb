{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train and test data\n",
    "train = pandas.read_csv(\"/Users/yezhenwang/Documents/Monash/Monash semester 2 2018/Quora/data/train.csv\")\n",
    "test = pandas.read_csv(\"/Users/yezhenwang/Documents/Monash/Monash semester 2 2018/Quora/data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check train and test\n",
    "# train.head()\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build question lists for train and test\n",
    "train_question_list = train[\"question_text\"].tolist()\n",
    "test_question_list = test[\"question_text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-0c34f4dc608e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_token_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_question_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_token_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# tokenize questions in test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[1;32m    128\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     return [token for sent in sentences\n\u001b[0m\u001b[1;32m    130\u001b[0m             for token in _treebank_word_tokenizer.tokenize(sent)]\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     return [token for sent in sentences\n\u001b[0;32m--> 130\u001b[0;31m             for token in _treebank_word_tokenizer.tokenize(sent)]\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/tokenize/treebank.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubstitution\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUNCTUATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstitution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# Handles parentheses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# tokenize questions in train\n",
    "train_token_list = []\n",
    "for i in train_question_list:\n",
    "    train_token_list.append(nltk.word_tokenize(i))\n",
    "    \n",
    "# tokenize questions in test\n",
    "test_token_list = []\n",
    "for i in test_question_list:\n",
    "    test_token_list.append(nltk.word_tokenize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag train_token_list\n",
    "train_token_tag = []\n",
    "for i in train_token_list:\n",
    "    train_token_tag.append(nltk.pos_tag(i))\n",
    "\n",
    "test_token_tag = []\n",
    "# tag test_token_list\n",
    "for i in test_token_list:\n",
    "    test_token_tag.append(nltk.pos_tag(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalize train and test tokenization\n",
    "train_token_tag_df = pd.DataFrame({\"question_text\": train_question_list,\n",
    "                                  \"tokened_question\": train_token_list,\n",
    "                                  \"tagged_question\": train_token_tag})\n",
    "\n",
    "test_token_tag_df = pd.DataFrame({\"question_text\": test_question_list,\n",
    "                                  \"tokened_question\": test_token_list,\n",
    "                                  \"tagged_question\": test_token_tag})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>tokened_question</th>\n",
       "      <th>tagged_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>[How, did, Quebec, nationalists, see, their, p...</td>\n",
       "      <td>[(How, WRB), (did, VBD), (Quebec, NNP), (natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>[Do, you, have, an, adopted, dog, ,, how, woul...</td>\n",
       "      <td>[(Do, VBP), (you, PRP), (have, VB), (an, DT), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>[Why, does, velocity, affect, time, ?, Does, v...</td>\n",
       "      <td>[(Why, WRB), (does, VBZ), (velocity, NN), (aff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>[How, did, Otto, von, Guericke, used, the, Mag...</td>\n",
       "      <td>[(How, WRB), (did, VBD), (Otto, NNP), (von, NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>[Can, I, convert, montra, helicon, D, to, a, m...</td>\n",
       "      <td>[(Can, MD), (I, PRP), (convert, VB), (montra, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question_text  \\\n",
       "0  How did Quebec nationalists see their province...   \n",
       "1  Do you have an adopted dog, how would you enco...   \n",
       "2  Why does velocity affect time? Does velocity a...   \n",
       "3  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "                                    tokened_question  \\\n",
       "0  [How, did, Quebec, nationalists, see, their, p...   \n",
       "1  [Do, you, have, an, adopted, dog, ,, how, woul...   \n",
       "2  [Why, does, velocity, affect, time, ?, Does, v...   \n",
       "3  [How, did, Otto, von, Guericke, used, the, Mag...   \n",
       "4  [Can, I, convert, montra, helicon, D, to, a, m...   \n",
       "\n",
       "                                     tagged_question  \n",
       "0  [(How, WRB), (did, VBD), (Quebec, NNP), (natio...  \n",
       "1  [(Do, VBP), (you, PRP), (have, VB), (an, DT), ...  \n",
       "2  [(Why, WRB), (does, VBZ), (velocity, NN), (aff...  \n",
       "3  [(How, WRB), (did, VBD), (Otto, NNP), (von, NN...  \n",
       "4  [(Can, MD), (I, PRP), (convert, VB), (montra, ...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_token_tag_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>tokened_question</th>\n",
       "      <th>tagged_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My voice range is A2-C5. My chest voice goes u...</td>\n",
       "      <td>[My, voice, range, is, A2-C5, ., My, chest, vo...</td>\n",
       "      <td>[(My, PRP$), (voice, NN), (range, NN), (is, VB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How much does a tutor earn in Bangalore?</td>\n",
       "      <td>[How, much, does, a, tutor, earn, in, Bangalor...</td>\n",
       "      <td>[(How, WRB), (much, JJ), (does, VBZ), (a, DT),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the best made pocket knives under $20...</td>\n",
       "      <td>[What, are, the, best, made, pocket, knives, u...</td>\n",
       "      <td>[(What, WP), (are, VBP), (the, DT), (best, JJS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why would they add a hypothetical scenario tha...</td>\n",
       "      <td>[Why, would, they, add, a, hypothetical, scena...</td>\n",
       "      <td>[(Why, WRB), (would, MD), (they, PRP), (add, V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the dresscode for Techmahindra freshers?</td>\n",
       "      <td>[What, is, the, dresscode, for, Techmahindra, ...</td>\n",
       "      <td>[(What, WP), (is, VBZ), (the, DT), (dresscode,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question_text  \\\n",
       "0  My voice range is A2-C5. My chest voice goes u...   \n",
       "1           How much does a tutor earn in Bangalore?   \n",
       "2  What are the best made pocket knives under $20...   \n",
       "3  Why would they add a hypothetical scenario tha...   \n",
       "4   What is the dresscode for Techmahindra freshers?   \n",
       "\n",
       "                                    tokened_question  \\\n",
       "0  [My, voice, range, is, A2-C5, ., My, chest, vo...   \n",
       "1  [How, much, does, a, tutor, earn, in, Bangalor...   \n",
       "2  [What, are, the, best, made, pocket, knives, u...   \n",
       "3  [Why, would, they, add, a, hypothetical, scena...   \n",
       "4  [What, is, the, dresscode, for, Techmahindra, ...   \n",
       "\n",
       "                                     tagged_question  \n",
       "0  [(My, PRP$), (voice, NN), (range, NN), (is, VB...  \n",
       "1  [(How, WRB), (much, JJ), (does, VBZ), (a, DT),...  \n",
       "2  [(What, WP), (are, VBP), (the, DT), (best, JJS...  \n",
       "3  [(Why, WRB), (would, MD), (they, PRP), (add, V...  \n",
       "4  [(What, WP), (is, VBZ), (the, DT), (dresscode,...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_token_tag_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What', 'WP'),\n",
       " ('are', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('best', 'JJS'),\n",
       " ('made', 'VBN'),\n",
       " ('pocket', 'NN'),\n",
       " ('knives', 'NNS'),\n",
       " ('under', 'IN'),\n",
       " ('$', '$'),\n",
       " ('200-300', 'CD'),\n",
       " ('?', '.')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_token_tag_df.tagged_question[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What are the best made pocket knives under $200-300?'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_token_tag_df.question_text[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
