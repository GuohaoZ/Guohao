{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. import data & libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import MWETokenizer\n",
    "#from nltk.corpus import wordnet\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from __future__ import division\n",
    "from itertools import chain\n",
    "from nltk.probability import *\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train and test data\n",
    "train = pandas.read_csv(\"/Users/yezhenwang/Documents/Monash/Monash semester 2 2018/Quora/data/train.csv\")\n",
    "test = pandas.read_csv(\"/Users/yezhenwang/Documents/Monash/Monash semester 2 2018/Quora/data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md          Tokenize.ipynb     \u001b[1m\u001b[36mall\u001b[m\u001b[m/               quora_demo1.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"all/train.csv\")\n",
    "test = pd.read_csv(\"all/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Randomly pick some data to chek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly pick rows from dataset\n",
    "# target = -1, don't care about it\n",
    "# target = 1, insincere\n",
    "# target = 0, normal label\n",
    "# default display count is 10.\n",
    "def pickRawDataByTarget(target, num=10):\n",
    "    random_list = []\n",
    "    if target == -1:\n",
    "        for i in range(num):\n",
    "            random_list.append(np.random.random_integers(len(train)+1))\n",
    "        for row in random_list:\n",
    "            print(\"Q:%d \\n%s || Target: %s\"%(row, train.iloc[row,1], train.iloc[row,2]))\n",
    "    else:\n",
    "        # Create a correspond target index list at first\n",
    "        targetList = (train[train['target'] == target].index).tolist()\n",
    "        for i in range(num):\n",
    "            random_list.append(np.random.random_integers(len(targetList)))\n",
    "        for index in random_list:\n",
    "            print(\"Q:%d \\n%s || Target: %s\"%(targetList[index], train.iloc[targetList[index],1], train.iloc[targetList[index],2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:1104471 \n",
      "Do you have that one skill or a set of few skills that you know will never desert you when you need it? How did you develop it? And how did you discover that those are the skills you wanted to develop? || Target: 0\n",
      "Q:203810 \n",
      "If a student worker on the F1 visa program works for 21 hours in a certain week just once by mistake I that a very serious offence? What imapct will it have on other H1B application in th future || Target: 0\n",
      "Q:1085416 \n",
      "Should I let my son watch porn and masturbate with his twin sister? || Target: 1\n",
      "Q:861616 \n",
      "What do you, as an atheist, think about Tim O'Neill and atheists who believe in the existence of Jesus and deny the history of Christian atrocities? || Target: 0\n",
      "Q:420564 \n",
      "What are the most effective techniques and procedures to perform a tubal ligation surgery? || Target: 0\n",
      "Q:166543 \n",
      "Whatre some of the best books to read for Java, application and system design? || Target: 0\n",
      "Q:1088805 \n",
      "When will Hindus rise up and invade the world? || Target: 1\n",
      "Q:1057398 \n",
      "What Are the best Granite colors for White Cabinets? || Target: 0\n",
      "Q:410641 \n",
      "I have learnt SAS and I am also going to learn R ,Apache spark.I was willing to do internship in Sas.Where do I apply? And what will my post be? || Target: 0\n",
      "Q:147088 \n",
      "Are Americans jealous of Canadians about anything? || Target: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/solar/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: This function is deprecated. Please call randint(1, 1306123 + 1) instead\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "pickRawDataByTarget(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_token_tag_df.iloc[819941,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lines might need caution\n",
    "1. No.338434 12th -> twelveth<br>\n",
    "2. No.1286381 Military Service: Capital case in the middle of sentence, check it whether could be bigram.\n",
    "3. No.968909 man-bun with \"-\"\n",
    "4. No.421977 22-Jun-2018, 'JJ' POS (I think it's Wrong?)\n",
    "5. No.819941 Rice production/distribution/processing, dealing with '/'\n",
    "    <br>Q: Stemming & N-gram order? (ref: https://stackoverflow.com/questions/47219389/compute-word-n-grams-on-original-text-or-after-lemma-stemming-process)\n",
    "6. No.1298566 mis-spelling.\n",
    "7. No.713198 ...Math question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Related Functions for pre-processing: case_Normaliztion, spec_Replacement, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_Normalize(line):\n",
    "    '''\n",
    "        'Originially used in my FIT5196 assignment, manully picked some end-tokens of a sentence'\n",
    "        Write a regex to match all words with a first capital letter in front of line or with some marks \n",
    "        ahead except the marks which would occur within a sentecne like [)(&,;-]. I think it not performed perfect but \n",
    "        it is better than sent_detector.tokenize()\n",
    "        \n",
    "        'Here is a caution in 5196, I'm not sure whether it happened here, but it seems no side-effect'\n",
    "        Caution: as data always contain many space tokens, I replace them with single space at first.\n",
    "    '''\n",
    "    casePattern = re.compile(r\"(^[A-Z]\\w*|[^\\w\\&,\\)\\(;-]\\s[A-Z][a-z]+)\")\n",
    "    # Some files have too many space tokens among two words in a sentecne\n",
    "    line = re.sub( '\\s+', ' ', line).strip()\n",
    "    # string.lower() used to normalise the capital letter.\n",
    "    return casePattern.sub(lambda x: x.group(0).lower(), line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_Replacement(line):\n",
    "    '''\n",
    "        A regex for split specific punctuation like '/'\n",
    "        1. replace '/' with ' or ' for furhter tokenize.\n",
    "        2. replace '%' with ' percentage'\n",
    "        3. replace '$' with 'dollar '\n",
    "    '''\n",
    "    line = re.sub( '\\/', ' or ', line).strip()\n",
    "    line = re.sub( '\\$', 'dollars ', line).strip()\n",
    "    line = re.sub( '\\%', ' percentage', line).strip()\n",
    "    \n",
    "\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any other functions here if need.\n",
    "# Add more functions inside #3 part. Then add them into pre-processing function\n",
    "def dealing_Non_Alphanumeric(line):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how can I invest in Rice production or distribution or processing in Nigeria?'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell used for simple test\n",
    "line1 = train.iloc[819941,1]\n",
    "line1 = re.sub( '\\s+', ' ', line1).strip()\n",
    "#line1\n",
    "line1 = case_Normalize(line1)\n",
    "spec_Replacement(line1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add related pre-processing function here\n",
    "def pre_process(line):\n",
    "    line = case_Normalize(line)\n",
    "    line = spec_Replacement(line)\n",
    "    \n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define funtion to get a stopword list\n",
    "# Default using nltk corpus.\n",
    "# Might add alterations.\n",
    "def get_StopWords():\n",
    "    return set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build question lists for train and test\n",
    "train_question_list = train[\"question_text\"].tolist()\n",
    "test_question_list = test[\"question_text\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q: Stemming or Lemmatization\n",
    "\n",
    "> In FIT5196, we are required to do stemming.<br>\n",
    "> https://stackoverflow.com/questions/49354665/should-i-perform-both-lemmatization-and-stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize questions in train\n",
    "train_token_list = []\n",
    "for i in train_question_list:\n",
    "    line = pre_process(i)\n",
    "    unigram_tokens = nltk.word_tokenize(line)\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    stemed_tokens = list(map(lambda x: stemmer.stem(x) if not x[0].isupper() else x, unigram_tokens))\n",
    "    stopped_tokens = [w for w in stemed_tokens if w not in get_StopWords()]\n",
    "    \n",
    "    # final_tokens remove any tokens have a tiny length (< 3)\n",
    "    final_tokens = list(filter(lambda x: len(x) >= 3, stopped_tokens))\n",
    "    train_token_list.append(final_tokens)\n",
    "    \n",
    "# tokenize questions in test\n",
    "test_token_list = []\n",
    "for i in test_question_list:\n",
    "    line = pre_process(i)\n",
    "    unigram_tokens = nltk.word_tokenize(line)\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    stemed_tokens = list(map(lambda x: stemmer.stem(x) if not x[0].isupper() else x, unigram_tokens))\n",
    "    stopped_tokens = [w for w in stemed_tokens if w not in get_StopWords()]\n",
    "    \n",
    "    # final_tokens remove any tokens have a tiny length (< 3)\n",
    "    final_tokens = list(filter(lambda x: len(x) >= 3, stopped_tokens))\n",
    "    train_token_list.append(final_tokens)\n",
    "    test_token_list.append(nltk.word_tokenize(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag train_token_list\n",
    "train_token_tag = []\n",
    "for i in train_token_list:\n",
    "    train_token_tag.append(nltk.pos_tag(i))\n",
    "\n",
    "test_token_tag = []\n",
    "# tag test_token_list\n",
    "for i in test_token_list:\n",
    "    test_token_tag.append(nltk.pos_tag(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalize train and test tokenization\n",
    "train_token_tag_df = pd.DataFrame({\"question_text\": train_question_list,\n",
    "                                  \"tokened_question\": train_token_list,\n",
    "                                  \"tagged_question\": train_token_tag})\n",
    "\n",
    "test_token_tag_df = pd.DataFrame({\"question_text\": test_question_list,\n",
    "                                  \"tokened_question\": test_token_list,\n",
    "                                  \"tagged_question\": test_token_tag})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_token_tag_df.iloc[103501,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>tokened_question</th>\n",
       "      <th>tagged_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>[How, did, Quebec, nationalists, see, their, p...</td>\n",
       "      <td>[(How, WRB), (did, VBD), (Quebec, NNP), (natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>[Do, you, have, an, adopted, dog, ,, how, woul...</td>\n",
       "      <td>[(Do, VBP), (you, PRP), (have, VB), (an, DT), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>[Why, does, velocity, affect, time, ?, Does, v...</td>\n",
       "      <td>[(Why, WRB), (does, VBZ), (velocity, NN), (aff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>[How, did, Otto, von, Guericke, used, the, Mag...</td>\n",
       "      <td>[(How, WRB), (did, VBD), (Otto, NNP), (von, NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>[Can, I, convert, montra, helicon, D, to, a, m...</td>\n",
       "      <td>[(Can, MD), (I, PRP), (convert, VB), (montra, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question_text  \\\n",
       "0  How did Quebec nationalists see their province...   \n",
       "1  Do you have an adopted dog, how would you enco...   \n",
       "2  Why does velocity affect time? Does velocity a...   \n",
       "3  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "                                    tokened_question  \\\n",
       "0  [How, did, Quebec, nationalists, see, their, p...   \n",
       "1  [Do, you, have, an, adopted, dog, ,, how, woul...   \n",
       "2  [Why, does, velocity, affect, time, ?, Does, v...   \n",
       "3  [How, did, Otto, von, Guericke, used, the, Mag...   \n",
       "4  [Can, I, convert, montra, helicon, D, to, a, m...   \n",
       "\n",
       "                                     tagged_question  \n",
       "0  [(How, WRB), (did, VBD), (Quebec, NNP), (natio...  \n",
       "1  [(Do, VBP), (you, PRP), (have, VB), (an, DT), ...  \n",
       "2  [(Why, WRB), (does, VBZ), (velocity, NN), (aff...  \n",
       "3  [(How, WRB), (did, VBD), (Otto, NNP), (von, NN...  \n",
       "4  [(Can, MD), (I, PRP), (convert, VB), (montra, ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_token_tag_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(train_token_tag_df) == len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>tokened_question</th>\n",
       "      <th>tagged_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My voice range is A2-C5. My chest voice goes u...</td>\n",
       "      <td>[My, voice, range, is, A2-C5, ., My, chest, vo...</td>\n",
       "      <td>[(My, PRP$), (voice, NN), (range, NN), (is, VB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How much does a tutor earn in Bangalore?</td>\n",
       "      <td>[How, much, does, a, tutor, earn, in, Bangalor...</td>\n",
       "      <td>[(How, WRB), (much, JJ), (does, VBZ), (a, DT),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the best made pocket knives under $20...</td>\n",
       "      <td>[What, are, the, best, made, pocket, knives, u...</td>\n",
       "      <td>[(What, WP), (are, VBP), (the, DT), (best, JJS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why would they add a hypothetical scenario tha...</td>\n",
       "      <td>[Why, would, they, add, a, hypothetical, scena...</td>\n",
       "      <td>[(Why, WRB), (would, MD), (they, PRP), (add, V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the dresscode for Techmahindra freshers?</td>\n",
       "      <td>[What, is, the, dresscode, for, Techmahindra, ...</td>\n",
       "      <td>[(What, WP), (is, VBZ), (the, DT), (dresscode,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question_text  \\\n",
       "0  My voice range is A2-C5. My chest voice goes u...   \n",
       "1           How much does a tutor earn in Bangalore?   \n",
       "2  What are the best made pocket knives under $20...   \n",
       "3  Why would they add a hypothetical scenario tha...   \n",
       "4   What is the dresscode for Techmahindra freshers?   \n",
       "\n",
       "                                    tokened_question  \\\n",
       "0  [My, voice, range, is, A2-C5, ., My, chest, vo...   \n",
       "1  [How, much, does, a, tutor, earn, in, Bangalor...   \n",
       "2  [What, are, the, best, made, pocket, knives, u...   \n",
       "3  [Why, would, they, add, a, hypothetical, scena...   \n",
       "4  [What, is, the, dresscode, for, Techmahindra, ...   \n",
       "\n",
       "                                     tagged_question  \n",
       "0  [(My, PRP$), (voice, NN), (range, NN), (is, VB...  \n",
       "1  [(How, WRB), (much, JJ), (does, VBZ), (a, DT),...  \n",
       "2  [(What, WP), (are, VBP), (the, DT), (best, JJS...  \n",
       "3  [(Why, WRB), (would, MD), (they, PRP), (add, V...  \n",
       "4  [(What, WP), (is, VBZ), (the, DT), (dresscode,...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_token_tag_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1278565",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-565567374eba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_token_tag_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagged_question\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1278565\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   3116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3117\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 3118\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   3119\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'boolean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1278565"
     ]
    }
   ],
   "source": [
    "test_token_tag_df.tagged_question[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What are the best made pocket knives under $200-300?'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_token_tag_df.question_text[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
